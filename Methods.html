<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Methods - Crop Disease Detection</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>

    <!-- Header -->
    <header>
        <h1>Crop Disease Detection Using CNNs and Federated Learning</h1>
    </header>

    <!-- Navigation -->
    <nav>
        <ul class="menu">
            <li><a href="index.html">Home</a></li>
            <li><a href="methods.html">Methods</a></li>
            <li><a href="results.html">Results</a></li>
            <li><a href="discussion.html">Discussion</a></li>
            <li><a href="conclusion.html">Conclusion</a></li>
            <li><a href="bibliography.html">References</a></li>
        </ul>
    </nav>

    <!-- Methods Content -->
    <section class="content-section">
        <h2>Methods</h2>

        <h3>1. Data Collection</h3>
        <p>
            The dataset used in this research is sourced from the <a href="https://plantvillage.psu.edu/" target="_blank">PlantVillage platform</a>. 
            This dataset contains over 50,000 images of healthy and infected plant leaves across various crops such as apples, grapes, corn, and tomatoes. 
            The dataset is pre-labeled and divided into different categories based on plant type and disease type, which provides a solid foundation for supervised learning tasks.
        </p>

        <h3>2. Data Preprocessing</h3>
        <p>
            Before training the models, we applied several preprocessing steps to the dataset to ensure consistency and improve the model’s ability to generalize:
        </p>
        <ul>
            <li>All images were resized to 224x224 pixels to maintain uniformity.</li>
            <li>Data augmentation techniques such as flipping, rotation, and zooming were applied to increase the diversity of the training dataset.</li>
            <li>Normalization was applied to ensure all pixel values are scaled between 0 and 1, which helps improve the convergence speed during training.</li>
        </ul>

        <h3>3. Model Architectures</h3>

        <h4>a. Convolutional Neural Networks (CNNs)</h4>
        <p>
            CNNs are widely used for image classification tasks and are particularly effective for detecting patterns in images. The architecture consists of multiple convolutional layers that extract features such as edges, shapes, and textures from the input images, followed by fully connected layers that make predictions. We used both ResNet50 and MobileNetV2 as part of our experiments.
        </p>

        <h4>b. ResNet50</h4>
        <p>
            ResNet50 is a deep convolutional neural network that solves the vanishing gradient problem by utilizing residual connections. This architecture allows for efficient training of very deep networks. 
            In our experiments, ResNet50 showed high performance, especially for more complex leaf disease classification tasks.
        </p>

        <h4>c. MobileNetV2</h4>
        <p>
            MobileNetV2 is a lightweight CNN model optimized for mobile and embedded devices. It uses depth-wise separable convolutions to reduce the number of parameters and computational cost while maintaining high accuracy. 
            This model was particularly useful in scenarios where computational efficiency was a priority, such as real-time crop disease detection on devices with limited hardware capabilities.
        </p>

        <h4>d. Vision Transformers (ViT)</h4>
        <p>
            Vision Transformers (ViTs) use attention mechanisms to capture global context across the entire image, unlike CNNs, which focus on local patterns. 
            ViTs provided strong performance in classifying complex disease patterns, but with a higher computational cost than CNNs.
        </p>

        <h3>4. Federated Learning</h3>
        <p>
            To address data privacy concerns, we implemented Federated Learning (FL), which allows models to be trained across multiple decentralized devices without the need to exchange raw data. 
            In this setup, each device (or client) trains its local model on its local dataset, and only model updates (e.g., gradients) are sent to a central server for aggregation. 
            This ensures that the raw data remains private and is never shared with a central server.
        </p>

        <p>
            The Federated Learning setup consisted of multiple rounds of local training and global model aggregation. We evaluated the effect of the number of clients, the number of communication rounds, and local epochs on model performance.
        </p>

        <!-- Example of an image (optional) -->
        <h3>Example of Preprocessing Pipeline</h3>
        <img src="images/data_augmentation.png" alt="Data Preprocessing Example" style="width:100%;max-width:600px;">
    </section>

    <!-- Footer -->
    <footer>
        <p>© 2024 Manan Patel. All rights reserved.</p>
    </footer>

</body>
</html>
